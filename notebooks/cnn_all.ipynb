{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for many subjects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero:\n",
    "\n",
    "Cargamos los datos y los normalizamos. Para esto, primero pasamos un filtro pasa-bajo de 0 a 20hz, luego lo normalizamos a $N(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/p300/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU's disponibles = ['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "import glob\n",
    "import os\n",
    "import mne\n",
    "from keras import backend as K\n",
    "from p300.preprocessing import normalize_subject, load_data\n",
    "\n",
    "print(\"GPU's disponibles = {}\".format(K.tensorflow_backend._get_available_gpus()))\n",
    "\n",
    "CORPORA_PATH = \"~/projects/corpora/P3Speller/P3Speller-old-y-datos/sets\"\n",
    "\n",
    "file_path = os.path.expanduser(CORPORA_PATH)\n",
    "files = glob.glob(os.path.join(file_path, \"*.set\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets appear as 2 in the third column\n",
    "\n",
    "\n",
    "We remove last channel as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# this line is to avoid output\n",
    "\n",
    "no_subjects_to_use = 30\n",
    "\n",
    "training_files = files[:no_subjects_to_use]\n",
    "testing_files = files[no_subjects_to_use:no_subjects_to_use+15]\n",
    "\n",
    "X_train, y_train = load_data(training_files)\n",
    "X_test, y_test = load_data(testing_files)\n",
    "\n",
    "X_train = X_train[:, :, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "y_t = y_train.reshape(-1)\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_t), y_t)\n",
    "\n",
    "class_weights = dict(zip([0,1], class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jmperez/.pyenv/versions/3.6.5/envs/p300/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/jmperez/.pyenv/versions/3.6.5/envs/p300/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "activation = 'relu'\n",
    "\n",
    "n_kernels = 15\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation=activation, input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(3*n_kernels, (1, 13), padding='same',\n",
    "                activation=activation))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(128, activation=activation))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52650 samples, validate on 5850 samples\n",
      "Epoch 1/20\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.7169 - acc: 0.5262Epoch 00001: val_loss improved from inf to 0.69207, saving model to model.h5\n",
      "52650/52650 [==============================] - 10s 194us/step - loss: 0.7169 - acc: 0.5267 - val_loss: 0.6921 - val_acc: 0.3942\n",
      "Epoch 2/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6768 - acc: 0.5795Epoch 00002: val_loss improved from 0.69207 to 0.69201, saving model to model.h5\n",
      "52650/52650 [==============================] - 5s 96us/step - loss: 0.6764 - acc: 0.5801 - val_loss: 0.6920 - val_acc: 0.6879\n",
      "Epoch 3/20\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.6657 - acc: 0.6118Epoch 00003: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.6654 - acc: 0.6121 - val_loss: 0.6945 - val_acc: 0.4674\n",
      "Epoch 4/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6551 - acc: 0.6283Epoch 00004: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.6551 - acc: 0.6274 - val_loss: 0.6932 - val_acc: 0.6359\n",
      "Epoch 5/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6437 - acc: 0.6489Epoch 00005: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.6440 - acc: 0.6488 - val_loss: 0.6938 - val_acc: 0.6694\n",
      "Epoch 6/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.6366 - acc: 0.6585Epoch 00006: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.6364 - acc: 0.6586 - val_loss: 0.7195 - val_acc: 0.7395\n",
      "Epoch 7/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.6268 - acc: 0.6702Epoch 00007: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.6266 - acc: 0.6702 - val_loss: 0.7247 - val_acc: 0.6957\n",
      "Epoch 8/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6167 - acc: 0.6723Epoch 00008: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.6169 - acc: 0.6727 - val_loss: 0.7120 - val_acc: 0.6463\n",
      "Epoch 9/20\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.6073 - acc: 0.6845Epoch 00009: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.6070 - acc: 0.6853 - val_loss: 0.7472 - val_acc: 0.7072\n",
      "Epoch 10/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.5974 - acc: 0.6917Epoch 00010: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.5970 - acc: 0.6917 - val_loss: 0.7659 - val_acc: 0.7140\n",
      "Epoch 11/20\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.6966Epoch 00011: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.5866 - acc: 0.6959 - val_loss: 0.7150 - val_acc: 0.5810\n",
      "Epoch 12/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.5796 - acc: 0.6991Epoch 00012: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 95us/step - loss: 0.5800 - acc: 0.6985 - val_loss: 0.7329 - val_acc: 0.5826\n",
      "Epoch 13/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.5737 - acc: 0.7032Epoch 00013: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 91us/step - loss: 0.5738 - acc: 0.7028 - val_loss: 0.7460 - val_acc: 0.6660\n",
      "Epoch 14/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.5654 - acc: 0.7108Epoch 00014: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.5655 - acc: 0.7107 - val_loss: 0.7974 - val_acc: 0.6603\n",
      "Epoch 15/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.5564 - acc: 0.7147Epoch 00015: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.5567 - acc: 0.7144 - val_loss: 0.7850 - val_acc: 0.6627\n",
      "Epoch 16/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.5484 - acc: 0.7219Epoch 00016: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.5481 - acc: 0.7218 - val_loss: 0.9612 - val_acc: 0.7576\n",
      "Epoch 17/20\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.5460 - acc: 0.7235Epoch 00017: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.5467 - acc: 0.7231 - val_loss: 0.7583 - val_acc: 0.5402\n",
      "Epoch 18/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.5393 - acc: 0.7286Epoch 00018: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.5394 - acc: 0.7288 - val_loss: 0.7602 - val_acc: 0.6075\n",
      "Epoch 19/20\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.5368 - acc: 0.7298Epoch 00019: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 93us/step - loss: 0.5363 - acc: 0.7302 - val_loss: 0.8955 - val_acc: 0.6928\n",
      "Epoch 20/20\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.5382 - acc: 0.7293Epoch 00020: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 94us/step - loss: 0.5383 - acc: 0.7293 - val_loss: 0.7915 - val_acc: 0.6159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb0d3c1ac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=20, \n",
    "    batch_size=256, class_weight=class_weights, validation_split=0.10,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.6395209580838324\n",
      "Precision  = 0.2071773220747889\n",
      "Recall     = 0.411377245508982\n",
      "ROC AUC    = 0.5703272735965196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.685395874916833\n",
      "Precision  = 0.23899518722854796\n",
      "Recall     = 0.4063872255489022\n",
      "ROC AUC    = 0.6088371679794105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_2 = load_model(\"model.h5\")\n",
    "\n",
    "y_pred = model_2.predict_classes(X_test)\n",
    "y_prob = model_2.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy   = 0.5315972222222223\n",
    "Precision  = 0.1865079365079365\n",
    "Recall     = 0.5385416666666667\n",
    "ROC AUC    = 0.5470785026041667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2842 - acc: 0.3579Epoch 00001: val_loss improved from inf to 1.22865, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 74us/step - loss: 1.2840 - acc: 0.3576 - val_loss: 1.2286 - val_acc: 0.3149\n",
      "Epoch 2/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.2306 - acc: 0.4305Epoch 00002: val_loss improved from 1.22865 to 1.21838, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2310 - acc: 0.4305 - val_loss: 1.2184 - val_acc: 0.2291\n",
      "Epoch 3/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.2226 - acc: 0.4576Epoch 00003: val_loss improved from 1.21838 to 1.19523, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2223 - acc: 0.4579 - val_loss: 1.1952 - val_acc: 0.4571\n",
      "Epoch 4/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.2129 - acc: 0.4866Epoch 00004: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2132 - acc: 0.4865 - val_loss: 1.1990 - val_acc: 0.4819\n",
      "Epoch 5/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.2049 - acc: 0.5096Epoch 00005: val_loss improved from 1.19523 to 1.17519, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2044 - acc: 0.5097 - val_loss: 1.1752 - val_acc: 0.5609\n",
      "Epoch 6/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1983 - acc: 0.5193Epoch 00006: val_loss improved from 1.17519 to 1.17201, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1983 - acc: 0.5194 - val_loss: 1.1720 - val_acc: 0.4187\n",
      "Epoch 7/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1951 - acc: 0.5159Epoch 00007: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1950 - acc: 0.5168 - val_loss: 1.1759 - val_acc: 0.4503\n",
      "Epoch 8/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5249Epoch 00008: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1934 - acc: 0.5250 - val_loss: 1.1799 - val_acc: 0.5316\n",
      "Epoch 9/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1864 - acc: 0.5308Epoch 00009: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1862 - acc: 0.5315 - val_loss: 1.1931 - val_acc: 0.3713\n",
      "Epoch 10/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1853 - acc: 0.5354Epoch 00010: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1851 - acc: 0.5353 - val_loss: 1.1799 - val_acc: 0.4334\n",
      "Epoch 11/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1806 - acc: 0.5418Epoch 00011: val_loss improved from 1.17201 to 1.16285, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1806 - acc: 0.5417 - val_loss: 1.1629 - val_acc: 0.5158\n",
      "Epoch 12/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1789 - acc: 0.5474Epoch 00012: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1790 - acc: 0.5464 - val_loss: 1.1676 - val_acc: 0.4921\n",
      "Epoch 13/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1761 - acc: 0.5466Epoch 00013: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1763 - acc: 0.5463 - val_loss: 1.1726 - val_acc: 0.4368\n",
      "Epoch 14/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.5444Epoch 00014: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1768 - acc: 0.5443 - val_loss: 1.1921 - val_acc: 0.4278\n",
      "Epoch 15/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1712 - acc: 0.5557Epoch 00015: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1714 - acc: 0.5552 - val_loss: 1.1732 - val_acc: 0.5203\n",
      "Epoch 16/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1710 - acc: 0.5541Epoch 00016: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1710 - acc: 0.5540 - val_loss: 1.1954 - val_acc: 0.5282\n",
      "Epoch 17/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1697 - acc: 0.5557Epoch 00017: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1701 - acc: 0.5555 - val_loss: 1.1818 - val_acc: 0.4729\n",
      "Epoch 18/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1696 - acc: 0.5573Epoch 00018: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1692 - acc: 0.5572 - val_loss: 1.1818 - val_acc: 0.5598\n",
      "Epoch 19/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1708 - acc: 0.5578Epoch 00019: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1706 - acc: 0.5582 - val_loss: 1.2023 - val_acc: 0.7223\n",
      "Epoch 20/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1665 - acc: 0.5650Epoch 00020: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1666 - acc: 0.5650 - val_loss: 1.1918 - val_acc: 0.4842\n",
      "Epoch 21/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1695 - acc: 0.5651Epoch 00021: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1694 - acc: 0.5652 - val_loss: 1.2015 - val_acc: 0.4865\n",
      "Epoch 22/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1673 - acc: 0.5679Epoch 00022: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1673 - acc: 0.5677 - val_loss: 1.2067 - val_acc: 0.5609\n",
      "Epoch 23/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1664 - acc: 0.5625Epoch 00023: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1664 - acc: 0.5628 - val_loss: 1.1967 - val_acc: 0.5068\n",
      "Epoch 24/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1680 - acc: 0.5622Epoch 00024: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1677 - acc: 0.5621 - val_loss: 1.1863 - val_acc: 0.6569\n",
      "Epoch 25/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1685 - acc: 0.5650Epoch 00025: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1681 - acc: 0.5649 - val_loss: 1.2268 - val_acc: 0.7190\n",
      "Epoch 26/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1654 - acc: 0.5734Epoch 00026: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 66us/step - loss: 1.1653 - acc: 0.5738 - val_loss: 1.2172 - val_acc: 0.5316\n",
      "Epoch 27/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1688 - acc: 0.5724Epoch 00027: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1688 - acc: 0.5725 - val_loss: 1.2068 - val_acc: 0.5023\n",
      "Epoch 28/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1673 - acc: 0.5697Epoch 00028: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1675 - acc: 0.5697 - val_loss: 1.2014 - val_acc: 0.4887\n",
      "Epoch 29/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1674 - acc: 0.5722Epoch 00029: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1679 - acc: 0.5715 - val_loss: 1.2151 - val_acc: 0.6738\n",
      "Epoch 30/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1721 - acc: 0.5714Epoch 00030: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1717 - acc: 0.5715 - val_loss: 1.2369 - val_acc: 0.6354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f8884048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.6778472222222223\n",
      "Precision  = 0.20906964656964658\n",
      "Recall     = 0.33520833333333333\n",
      "ROC AUC    = 0.5621011501736111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(2*n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(2*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2579 - acc: 0.2898Epoch 00001: val_loss improved from inf to 1.23357, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 9s 97us/step - loss: 1.2578 - acc: 0.2909 - val_loss: 1.2336 - val_acc: 0.3059\n",
      "Epoch 2/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2382 - acc: 0.4181Epoch 00002: val_loss improved from 1.23357 to 1.22315, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2384 - acc: 0.4181 - val_loss: 1.2232 - val_acc: 0.3341\n",
      "Epoch 3/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2305 - acc: 0.4623Epoch 00003: val_loss improved from 1.22315 to 1.21358, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2309 - acc: 0.4623 - val_loss: 1.2136 - val_acc: 0.4300\n",
      "Epoch 4/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2240 - acc: 0.4711Epoch 00004: val_loss improved from 1.21358 to 1.20041, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2239 - acc: 0.4719 - val_loss: 1.2004 - val_acc: 0.5609\n",
      "Epoch 5/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2180 - acc: 0.4968Epoch 00005: val_loss improved from 1.20041 to 1.19120, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2187 - acc: 0.4972 - val_loss: 1.1912 - val_acc: 0.4447\n",
      "Epoch 6/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.4846Epoch 00006: val_loss improved from 1.19120 to 1.18859, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2165 - acc: 0.4848 - val_loss: 1.1886 - val_acc: 0.4808\n",
      "Epoch 7/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2146 - acc: 0.5035Epoch 00007: val_loss improved from 1.18859 to 1.18811, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2145 - acc: 0.5036 - val_loss: 1.1881 - val_acc: 0.5068\n",
      "Epoch 8/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2128 - acc: 0.5062Epoch 00008: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2130 - acc: 0.5065 - val_loss: 1.1937 - val_acc: 0.4695\n",
      "Epoch 9/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2096 - acc: 0.5042Epoch 00009: val_loss improved from 1.18811 to 1.18605, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2098 - acc: 0.5034 - val_loss: 1.1861 - val_acc: 0.4944\n",
      "Epoch 10/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2102 - acc: 0.5025Epoch 00010: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2096 - acc: 0.5022 - val_loss: 1.1982 - val_acc: 0.5372\n",
      "Epoch 11/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2056 - acc: 0.5100Epoch 00011: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 83us/step - loss: 1.2053 - acc: 0.5102 - val_loss: 1.2001 - val_acc: 0.5192\n",
      "Epoch 12/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2089 - acc: 0.5082Epoch 00012: val_loss improved from 1.18605 to 1.18120, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2084 - acc: 0.5080 - val_loss: 1.1812 - val_acc: 0.5892\n",
      "Epoch 13/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2066 - acc: 0.5105Epoch 00013: val_loss improved from 1.18120 to 1.17853, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2063 - acc: 0.5108 - val_loss: 1.1785 - val_acc: 0.6005\n",
      "Epoch 14/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2039 - acc: 0.5178Epoch 00014: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2040 - acc: 0.5176 - val_loss: 1.1920 - val_acc: 0.5790\n",
      "Epoch 15/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2034 - acc: 0.5219Epoch 00015: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2036 - acc: 0.5214 - val_loss: 1.1926 - val_acc: 0.4819\n",
      "Epoch 16/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5125Epoch 00016: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2008 - acc: 0.5123 - val_loss: 1.1882 - val_acc: 0.5192\n",
      "Epoch 17/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2029 - acc: 0.5150Epoch 00017: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2024 - acc: 0.5146 - val_loss: 1.1859 - val_acc: 0.4808\n",
      "Epoch 18/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5163Epoch 00018: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1989 - acc: 0.5162 - val_loss: 1.1935 - val_acc: 0.5609\n",
      "Epoch 19/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1986 - acc: 0.5195Epoch 00019: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1983 - acc: 0.5194 - val_loss: 1.1957 - val_acc: 0.6027\n",
      "Epoch 20/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2001 - acc: 0.5298Epoch 00020: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2000 - acc: 0.5299 - val_loss: 1.1886 - val_acc: 0.5102\n",
      "Epoch 21/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1973 - acc: 0.5305Epoch 00021: val_loss improved from 1.17853 to 1.17227, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1972 - acc: 0.5306 - val_loss: 1.1723 - val_acc: 0.5282\n",
      "Epoch 22/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5220Epoch 00022: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1987 - acc: 0.5221 - val_loss: 1.1828 - val_acc: 0.5564\n",
      "Epoch 23/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2017 - acc: 0.5264Epoch 00023: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2023 - acc: 0.5266 - val_loss: 1.2311 - val_acc: 0.4921\n",
      "Epoch 24/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5248Epoch 00024: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2016 - acc: 0.5249 - val_loss: 1.2268 - val_acc: 0.5508\n",
      "Epoch 25/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2047 - acc: 0.5183Epoch 00025: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2053 - acc: 0.5186 - val_loss: 1.1934 - val_acc: 0.5508\n",
      "Epoch 26/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1973 - acc: 0.5213Epoch 00026: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1975 - acc: 0.5215 - val_loss: 1.1883 - val_acc: 0.5858\n",
      "Epoch 27/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.5303Epoch 00027: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1969 - acc: 0.5307 - val_loss: 1.1782 - val_acc: 0.6174\n",
      "Epoch 28/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1943 - acc: 0.5416Epoch 00028: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1947 - acc: 0.5415 - val_loss: 1.1951 - val_acc: 0.5519\n",
      "Epoch 29/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5352Epoch 00029: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 86us/step - loss: 1.1934 - acc: 0.5357 - val_loss: 1.2028 - val_acc: 0.6275\n",
      "Epoch 30/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1950 - acc: 0.5363Epoch 00030: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 83us/step - loss: 1.1951 - acc: 0.5362 - val_loss: 1.1984 - val_acc: 0.4650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f3efd5c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.4284375\n",
      "Precision  = 0.18658280922431866\n",
      "Recall     = 0.723125\n",
      "ROC AUC    = 0.5781777647569444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with two layers but one simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(2*n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Conv2D(n_kernels, (14, 5), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2611 - acc: 0.3341Epoch 00001: val_loss improved from inf to 1.23793, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 8s 88us/step - loss: 1.2603 - acc: 0.3354 - val_loss: 1.2379 - val_acc: 0.6806\n",
      "Epoch 2/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2389 - acc: 0.4354Epoch 00002: val_loss improved from 1.23793 to 1.23455, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 77us/step - loss: 1.2385 - acc: 0.4356 - val_loss: 1.2346 - val_acc: 0.5023\n",
      "Epoch 3/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2300 - acc: 0.4530Epoch 00003: val_loss improved from 1.23455 to 1.23216, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2303 - acc: 0.4524 - val_loss: 1.2322 - val_acc: 0.3296\n",
      "Epoch 4/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2259 - acc: 0.4696Epoch 00004: val_loss improved from 1.23216 to 1.20799, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2262 - acc: 0.4699 - val_loss: 1.2080 - val_acc: 0.4707\n",
      "Epoch 5/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.4933Epoch 00005: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2189 - acc: 0.4926 - val_loss: 1.2386 - val_acc: 0.2269\n",
      "Epoch 6/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2161 - acc: 0.4894Epoch 00006: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2165 - acc: 0.4894 - val_loss: 1.2285 - val_acc: 0.4289\n",
      "Epoch 7/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2121 - acc: 0.5043Epoch 00007: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2120 - acc: 0.5042 - val_loss: 1.2172 - val_acc: 0.4774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f3f581d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.48006944444444444\n",
      "Precision  = 0.19064704451471662\n",
      "Recall     = 0.653125\n",
      "ROC AUC    = 0.5707269444444445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
