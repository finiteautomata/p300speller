{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for many subjects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero:\n",
    "\n",
    "Cargamos los datos y los normalizamos. Para esto, primero pasamos un filtro pasa-bajo de 0 a 20hz, luego lo normalizamos a $N(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/p300/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU's disponibles = ['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "import glob\n",
    "import os\n",
    "import mne\n",
    "from keras import backend as K\n",
    "from p300.preprocessing import normalize_subject, load_data\n",
    "\n",
    "print(\"GPU's disponibles = {}\".format(K.tensorflow_backend._get_available_gpus()))\n",
    "\n",
    "CORPORA_PATH = \"~/projects/corpora/P3Speller/P3Speller-old-y-datos/sets\"\n",
    "\n",
    "file_path = os.path.expanduser(CORPORA_PATH)\n",
    "files = glob.glob(os.path.join(file_path, \"*.set\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets appear as 2 in the third column\n",
    "\n",
    "\n",
    "We remove last channel as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# this line is to avoid output\n",
    "\n",
    "no_subjects_to_use = 30\n",
    "\n",
    "training_files = files[:no_subjects_to_use]\n",
    "\n",
    "\n",
    "X_train, y_train = load_data(training_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.6, 1: 3.0}\n",
      "(58500, 14, 104, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "y_t = y_train.reshape(-1)\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_t), y_t)\n",
    "\n",
    "class_weights = dict(zip([0,1], class_weights))\n",
    "\n",
    "print(\"Class weights: {}\".format(class_weights))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jmperez/.pyenv/versions/3.6.5/envs/p300/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1264: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/jmperez/.pyenv/versions/3.6.5/envs/p300/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "activation = 'relu'\n",
    "\n",
    "n_kernels = 12\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same',\n",
    "                activation=activation, input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation=activation))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(128, activation=activation))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52650 samples, validate on 5850 samples\n",
      "Epoch 1/40\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.7343 - acc: 0.5383Epoch 00001: val_loss improved from inf to 0.69256, saving model to models/model_cnn_1.h5\n",
      "52650/52650 [==============================] - 11s 208us/step - loss: 0.7339 - acc: 0.5395 - val_loss: 0.6926 - val_acc: 0.4202\n",
      "Epoch 2/40\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6735 - acc: 0.5862Epoch 00002: val_loss improved from 0.69256 to 0.69134, saving model to models/model_cnn_1.h5\n",
      "52650/52650 [==============================] - 6s 109us/step - loss: 0.6739 - acc: 0.5862 - val_loss: 0.6913 - val_acc: 0.5726\n",
      "Epoch 3/40\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6614 - acc: 0.6256Epoch 00003: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 104us/step - loss: 0.6611 - acc: 0.6253 - val_loss: 0.7092 - val_acc: 0.6215\n",
      "Epoch 4/40\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.6409Epoch 00004: val_loss did not improve\n",
      "52650/52650 [==============================] - 6s 105us/step - loss: 0.6511 - acc: 0.6402 - val_loss: 0.7434 - val_acc: 0.7844\n",
      "Epoch 5/40\n",
      "52224/52650 [============================>.] - ETA: 0s - loss: 0.6414 - acc: 0.6594Epoch 00005: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 104us/step - loss: 0.6414 - acc: 0.6590 - val_loss: 0.7048 - val_acc: 0.7195\n",
      "Epoch 6/40\n",
      "52480/52650 [============================>.] - ETA: 0s - loss: 0.6328 - acc: 0.6709Epoch 00006: val_loss did not improve\n",
      "52650/52650 [==============================] - 6s 105us/step - loss: 0.6331 - acc: 0.6710 - val_loss: 0.6982 - val_acc: 0.5402\n",
      "Epoch 7/40\n",
      "51968/52650 [============================>.] - ETA: 0s - loss: 0.6238 - acc: 0.6812Epoch 00007: val_loss did not improve\n",
      "52650/52650 [==============================] - 5s 104us/step - loss: 0.6239 - acc: 0.6808 - val_loss: 0.7292 - val_acc: 0.6629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83fc39f7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='models/model_cnn_1.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=40, \n",
    "    batch_size=256, class_weight=class_weights, validation_split=0.10,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the first four layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<keras.layers.convolutional.Conv2D at 0x7f83f9531a20>, 'Trainable: False'),\n",
       " (<keras.layers.convolutional.Conv2D at 0x7f83f95319b0>, 'Trainable: False'),\n",
       " (<keras.layers.core.Flatten at 0x7f83fc0f4b00>, 'Trainable: False'),\n",
       " (<keras.layers.core.Dropout at 0x7f83f95ab0f0>, 'Trainable: False'),\n",
       " (<keras.layers.core.Dense at 0x7f83f95b0d30>, 'Trainable: True'),\n",
       " (<keras.layers.core.Dense at 0x7f83f95b0f60>, 'Trainable: True')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(4):\n",
    "    model.layers[i].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy\n",
    "[(l, \"Trainable: {}\".format(l.trainable)) for l in model.layers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the idea is to train each subject and fine tune the last layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from p300.preprocessing import normalize_subject, load_data, load_data_from_subject\n",
    "\n",
    "file = files[130]\n",
    "\n",
    "X_sub, y_sub = load_data([file])\n",
    "\n",
    "length = X_sub.shape[0] \n",
    "limit = int(length / 2)\n",
    "X_sub_train, X_sub_test = X_sub[:limit], X_sub[limit:]\n",
    "y_sub_train, y_sub_test = y_sub[:limit], y_sub[limit:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900, 14, 104, 1), (900, 14, 104, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub_train.shape, X_sub_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples, validate on 9 samples\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 2s 2ms/step - loss: 1.2490 - acc: 0.6655 - val_loss: 1.0674 - val_acc: 0.7778\n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s 190us/step - loss: 1.0958 - acc: 0.6510 - val_loss: 1.0377 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s 155us/step - loss: 0.9691 - acc: 0.7228 - val_loss: 0.9565 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.8743 - acc: 0.7823 - val_loss: 0.9199 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s 153us/step - loss: 0.7802 - acc: 0.7991 - val_loss: 0.9024 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.6782 - acc: 0.8507 - val_loss: 0.8324 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.5877 - acc: 0.8743 - val_loss: 0.9087 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.4985 - acc: 0.9057 - val_loss: 1.0205 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s 149us/step - loss: 0.4271 - acc: 0.9270 - val_loss: 0.8588 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s 151us/step - loss: 0.3543 - acc: 0.9484 - val_loss: 0.9490 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8370668ac8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        X_sub_train, y_sub_train, epochs=10, \n",
    "        batch_size=64, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "        callbacks=[early_stopping]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy   = 0.7488888888888889\n",
      "    Precision  = 0.3\n",
      "    Recall     = 0.38\n",
      "    ROC AUC    = 0.6240711111111111\n",
      "    F1         = 0.3352941176470588\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "def print_results(model, X_test, y_test):\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    y_prob = model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\"\"\n",
    "    Accuracy   = {}\n",
    "    Precision  = {}\n",
    "    Recall     = {}\n",
    "    ROC AUC    = {}\n",
    "    F1         = {}\n",
    "    \"\"\".format(accuracy, precision, recall, auc, f1))\n",
    "    \n",
    "print_results(model, X_sub_test, y_sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fix_layers(model, fixed_layers):\n",
    "    for i in range(fixed_layers):\n",
    "        model.layers[i].trainable = False\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def fine_tune(model, fixed_layers):\n",
    "    fix_layers(model, fixed_layers)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train, epochs=10, \n",
    "        batch_size=64, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_analysis(filename, fixed_layers=4):\n",
    "    K.clear_session()\n",
    "    X, y = load_data(files[143])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, stratify=y)\n",
    "    \n",
    "    ret = {\"file\" : basename(filename)}\n",
    "    metrics = {\"ft_0_{}\".format(k):v for k,v in get_metrics(model, X_test, y_test).items()}\n",
    "    ret.update(metrics)\n",
    "    \n",
    "    model = fine_tune(4)\n",
    "    metrics = {\"ft_4_{}\".format(k):v for k,v in get_metrics(model, X_test, y_test).items()}\n",
    "    ret.update(metrics)\n",
    "    \n",
    "    model = fine_tune(5)\n",
    "    metrics = {\"ft_5_{}\".format(k):v for k,v in get_metrics(model, X_test, y_test).items()}\n",
    "    ret.update(metrics)\n",
    "    \n",
    "    K.clear_session()\n",
    "    return ret\n",
    "\n",
    "get_analysis(files[100], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy   = 0.5842592592592593\n",
      "    Precision  = 0.22590384179938108\n",
      "    Recall     = 0.6158436213991769\n",
      "    ROC AUC    = 0.6375042930447594\n",
      "    F1         = 0.3305538682423105\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def print_results(model):\n",
    "    y_pred = model.predict_classes(X_test)\n",
    "    y_prob = model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    print(\"\"\"\n",
    "    Accuracy   = {}\n",
    "    Precision  = {}\n",
    "    Recall     = {}\n",
    "    ROC AUC    = {}\n",
    "    F1         = {}\n",
    "    \"\"\".format(accuracy, precision, recall, auc, f1))\n",
    "    \n",
    "\n",
    "print_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Accuracy   = 0.6500342935528121\n",
      "    Precision  = 0.24240963855421688\n",
      "    Recall     = 0.5174897119341564\n",
      "    ROC AUC    = 0.6364045919490593\n",
      "    F1         = 0.33016081391532653\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_2 = load_model('models/model_cnn_1.h5')\n",
    "\n",
    "print_results(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2842 - acc: 0.3579Epoch 00001: val_loss improved from inf to 1.22865, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 74us/step - loss: 1.2840 - acc: 0.3576 - val_loss: 1.2286 - val_acc: 0.3149\n",
      "Epoch 2/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.2306 - acc: 0.4305Epoch 00002: val_loss improved from 1.22865 to 1.21838, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2310 - acc: 0.4305 - val_loss: 1.2184 - val_acc: 0.2291\n",
      "Epoch 3/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.2226 - acc: 0.4576Epoch 00003: val_loss improved from 1.21838 to 1.19523, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2223 - acc: 0.4579 - val_loss: 1.1952 - val_acc: 0.4571\n",
      "Epoch 4/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.2129 - acc: 0.4866Epoch 00004: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2132 - acc: 0.4865 - val_loss: 1.1990 - val_acc: 0.4819\n",
      "Epoch 5/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.2049 - acc: 0.5096Epoch 00005: val_loss improved from 1.19523 to 1.17519, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2044 - acc: 0.5097 - val_loss: 1.1752 - val_acc: 0.5609\n",
      "Epoch 6/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1983 - acc: 0.5193Epoch 00006: val_loss improved from 1.17519 to 1.17201, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1983 - acc: 0.5194 - val_loss: 1.1720 - val_acc: 0.4187\n",
      "Epoch 7/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1951 - acc: 0.5159Epoch 00007: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1950 - acc: 0.5168 - val_loss: 1.1759 - val_acc: 0.4503\n",
      "Epoch 8/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5249Epoch 00008: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1934 - acc: 0.5250 - val_loss: 1.1799 - val_acc: 0.5316\n",
      "Epoch 9/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1864 - acc: 0.5308Epoch 00009: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1862 - acc: 0.5315 - val_loss: 1.1931 - val_acc: 0.3713\n",
      "Epoch 10/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1853 - acc: 0.5354Epoch 00010: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1851 - acc: 0.5353 - val_loss: 1.1799 - val_acc: 0.4334\n",
      "Epoch 11/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1806 - acc: 0.5418Epoch 00011: val_loss improved from 1.17201 to 1.16285, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1806 - acc: 0.5417 - val_loss: 1.1629 - val_acc: 0.5158\n",
      "Epoch 12/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1789 - acc: 0.5474Epoch 00012: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1790 - acc: 0.5464 - val_loss: 1.1676 - val_acc: 0.4921\n",
      "Epoch 13/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1761 - acc: 0.5466Epoch 00013: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1763 - acc: 0.5463 - val_loss: 1.1726 - val_acc: 0.4368\n",
      "Epoch 14/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.5444Epoch 00014: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1768 - acc: 0.5443 - val_loss: 1.1921 - val_acc: 0.4278\n",
      "Epoch 15/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1712 - acc: 0.5557Epoch 00015: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1714 - acc: 0.5552 - val_loss: 1.1732 - val_acc: 0.5203\n",
      "Epoch 16/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1710 - acc: 0.5541Epoch 00016: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1710 - acc: 0.5540 - val_loss: 1.1954 - val_acc: 0.5282\n",
      "Epoch 17/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1697 - acc: 0.5557Epoch 00017: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1701 - acc: 0.5555 - val_loss: 1.1818 - val_acc: 0.4729\n",
      "Epoch 18/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1696 - acc: 0.5573Epoch 00018: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1692 - acc: 0.5572 - val_loss: 1.1818 - val_acc: 0.5598\n",
      "Epoch 19/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1708 - acc: 0.5578Epoch 00019: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1706 - acc: 0.5582 - val_loss: 1.2023 - val_acc: 0.7223\n",
      "Epoch 20/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1665 - acc: 0.5650Epoch 00020: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1666 - acc: 0.5650 - val_loss: 1.1918 - val_acc: 0.4842\n",
      "Epoch 21/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1695 - acc: 0.5651Epoch 00021: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1694 - acc: 0.5652 - val_loss: 1.2015 - val_acc: 0.4865\n",
      "Epoch 22/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1673 - acc: 0.5679Epoch 00022: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1673 - acc: 0.5677 - val_loss: 1.2067 - val_acc: 0.5609\n",
      "Epoch 23/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1664 - acc: 0.5625Epoch 00023: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1664 - acc: 0.5628 - val_loss: 1.1967 - val_acc: 0.5068\n",
      "Epoch 24/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1680 - acc: 0.5622Epoch 00024: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1677 - acc: 0.5621 - val_loss: 1.1863 - val_acc: 0.6569\n",
      "Epoch 25/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1685 - acc: 0.5650Epoch 00025: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1681 - acc: 0.5649 - val_loss: 1.2268 - val_acc: 0.7190\n",
      "Epoch 26/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1654 - acc: 0.5734Epoch 00026: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 66us/step - loss: 1.1653 - acc: 0.5738 - val_loss: 1.2172 - val_acc: 0.5316\n",
      "Epoch 27/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1688 - acc: 0.5724Epoch 00027: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1688 - acc: 0.5725 - val_loss: 1.2068 - val_acc: 0.5023\n",
      "Epoch 28/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1673 - acc: 0.5697Epoch 00028: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1675 - acc: 0.5697 - val_loss: 1.2014 - val_acc: 0.4887\n",
      "Epoch 29/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1674 - acc: 0.5722Epoch 00029: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1679 - acc: 0.5715 - val_loss: 1.2151 - val_acc: 0.6738\n",
      "Epoch 30/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1721 - acc: 0.5714Epoch 00030: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1717 - acc: 0.5715 - val_loss: 1.2369 - val_acc: 0.6354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f8884048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='models/model_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.6778472222222223\n",
      "Precision  = 0.20906964656964658\n",
      "Recall     = 0.33520833333333333\n",
      "ROC AUC    = 0.5621011501736111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(2*n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(2*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2579 - acc: 0.2898Epoch 00001: val_loss improved from inf to 1.23357, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 9s 97us/step - loss: 1.2578 - acc: 0.2909 - val_loss: 1.2336 - val_acc: 0.3059\n",
      "Epoch 2/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2382 - acc: 0.4181Epoch 00002: val_loss improved from 1.23357 to 1.22315, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2384 - acc: 0.4181 - val_loss: 1.2232 - val_acc: 0.3341\n",
      "Epoch 3/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2305 - acc: 0.4623Epoch 00003: val_loss improved from 1.22315 to 1.21358, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2309 - acc: 0.4623 - val_loss: 1.2136 - val_acc: 0.4300\n",
      "Epoch 4/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2240 - acc: 0.4711Epoch 00004: val_loss improved from 1.21358 to 1.20041, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2239 - acc: 0.4719 - val_loss: 1.2004 - val_acc: 0.5609\n",
      "Epoch 5/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2180 - acc: 0.4968Epoch 00005: val_loss improved from 1.20041 to 1.19120, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2187 - acc: 0.4972 - val_loss: 1.1912 - val_acc: 0.4447\n",
      "Epoch 6/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.4846Epoch 00006: val_loss improved from 1.19120 to 1.18859, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2165 - acc: 0.4848 - val_loss: 1.1886 - val_acc: 0.4808\n",
      "Epoch 7/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2146 - acc: 0.5035Epoch 00007: val_loss improved from 1.18859 to 1.18811, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2145 - acc: 0.5036 - val_loss: 1.1881 - val_acc: 0.5068\n",
      "Epoch 8/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2128 - acc: 0.5062Epoch 00008: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2130 - acc: 0.5065 - val_loss: 1.1937 - val_acc: 0.4695\n",
      "Epoch 9/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2096 - acc: 0.5042Epoch 00009: val_loss improved from 1.18811 to 1.18605, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2098 - acc: 0.5034 - val_loss: 1.1861 - val_acc: 0.4944\n",
      "Epoch 10/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2102 - acc: 0.5025Epoch 00010: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2096 - acc: 0.5022 - val_loss: 1.1982 - val_acc: 0.5372\n",
      "Epoch 11/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2056 - acc: 0.5100Epoch 00011: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 83us/step - loss: 1.2053 - acc: 0.5102 - val_loss: 1.2001 - val_acc: 0.5192\n",
      "Epoch 12/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2089 - acc: 0.5082Epoch 00012: val_loss improved from 1.18605 to 1.18120, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2084 - acc: 0.5080 - val_loss: 1.1812 - val_acc: 0.5892\n",
      "Epoch 13/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2066 - acc: 0.5105Epoch 00013: val_loss improved from 1.18120 to 1.17853, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2063 - acc: 0.5108 - val_loss: 1.1785 - val_acc: 0.6005\n",
      "Epoch 14/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2039 - acc: 0.5178Epoch 00014: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2040 - acc: 0.5176 - val_loss: 1.1920 - val_acc: 0.5790\n",
      "Epoch 15/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2034 - acc: 0.5219Epoch 00015: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2036 - acc: 0.5214 - val_loss: 1.1926 - val_acc: 0.4819\n",
      "Epoch 16/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5125Epoch 00016: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2008 - acc: 0.5123 - val_loss: 1.1882 - val_acc: 0.5192\n",
      "Epoch 17/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2029 - acc: 0.5150Epoch 00017: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2024 - acc: 0.5146 - val_loss: 1.1859 - val_acc: 0.4808\n",
      "Epoch 18/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5163Epoch 00018: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1989 - acc: 0.5162 - val_loss: 1.1935 - val_acc: 0.5609\n",
      "Epoch 19/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1986 - acc: 0.5195Epoch 00019: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1983 - acc: 0.5194 - val_loss: 1.1957 - val_acc: 0.6027\n",
      "Epoch 20/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2001 - acc: 0.5298Epoch 00020: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2000 - acc: 0.5299 - val_loss: 1.1886 - val_acc: 0.5102\n",
      "Epoch 21/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1973 - acc: 0.5305Epoch 00021: val_loss improved from 1.17853 to 1.17227, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1972 - acc: 0.5306 - val_loss: 1.1723 - val_acc: 0.5282\n",
      "Epoch 22/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5220Epoch 00022: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1987 - acc: 0.5221 - val_loss: 1.1828 - val_acc: 0.5564\n",
      "Epoch 23/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2017 - acc: 0.5264Epoch 00023: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2023 - acc: 0.5266 - val_loss: 1.2311 - val_acc: 0.4921\n",
      "Epoch 24/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5248Epoch 00024: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2016 - acc: 0.5249 - val_loss: 1.2268 - val_acc: 0.5508\n",
      "Epoch 25/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2047 - acc: 0.5183Epoch 00025: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2053 - acc: 0.5186 - val_loss: 1.1934 - val_acc: 0.5508\n",
      "Epoch 26/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1973 - acc: 0.5213Epoch 00026: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1975 - acc: 0.5215 - val_loss: 1.1883 - val_acc: 0.5858\n",
      "Epoch 27/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.5303Epoch 00027: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1969 - acc: 0.5307 - val_loss: 1.1782 - val_acc: 0.6174\n",
      "Epoch 28/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1943 - acc: 0.5416Epoch 00028: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1947 - acc: 0.5415 - val_loss: 1.1951 - val_acc: 0.5519\n",
      "Epoch 29/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5352Epoch 00029: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 86us/step - loss: 1.1934 - acc: 0.5357 - val_loss: 1.2028 - val_acc: 0.6275\n",
      "Epoch 30/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1950 - acc: 0.5363Epoch 00030: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 83us/step - loss: 1.1951 - acc: 0.5362 - val_loss: 1.1984 - val_acc: 0.4650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f3efd5c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.4284375\n",
      "Precision  = 0.18658280922431866\n",
      "Recall     = 0.723125\n",
      "ROC AUC    = 0.5781777647569444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with two layers but one simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2611 - acc: 0.3341Epoch 00001: val_loss improved from inf to 1.23793, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 8s 88us/step - loss: 1.2603 - acc: 0.3354 - val_loss: 1.2379 - val_acc: 0.6806\n",
      "Epoch 2/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2389 - acc: 0.4354Epoch 00002: val_loss improved from 1.23793 to 1.23455, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 77us/step - loss: 1.2385 - acc: 0.4356 - val_loss: 1.2346 - val_acc: 0.5023\n",
      "Epoch 3/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2300 - acc: 0.4530Epoch 00003: val_loss improved from 1.23455 to 1.23216, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2303 - acc: 0.4524 - val_loss: 1.2322 - val_acc: 0.3296\n",
      "Epoch 4/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2259 - acc: 0.4696Epoch 00004: val_loss improved from 1.23216 to 1.20799, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2262 - acc: 0.4699 - val_loss: 1.2080 - val_acc: 0.4707\n",
      "Epoch 5/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.4933Epoch 00005: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2189 - acc: 0.4926 - val_loss: 1.2386 - val_acc: 0.2269\n",
      "Epoch 6/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2161 - acc: 0.4894Epoch 00006: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2165 - acc: 0.4894 - val_loss: 1.2285 - val_acc: 0.4289\n",
      "Epoch 7/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2121 - acc: 0.5043Epoch 00007: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2120 - acc: 0.5042 - val_loss: 1.2172 - val_acc: 0.4774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f3f581d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.48006944444444444\n",
      "Precision  = 0.19064704451471662\n",
      "Recall     = 0.653125\n",
      "ROC AUC    = 0.5707269444444445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
