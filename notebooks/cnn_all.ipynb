{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for many subjects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero:\n",
    "\n",
    "Cargamos los datos y los normalizamos. Para esto, primero pasamos un filtro pasa-bajo de 0 a 20hz, luego lo normalizamos a $N(0, 1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "GPU's disponibles = ['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1']\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import mne\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "print(\"GPU's disponibles = {}\".format(K.tensorflow_backend._get_available_gpus()))\n",
    "\n",
    "CORPORA_PATH = \"/home/jmperez/projects/corpora/P3Speller/P3Speller-old-y-datos/sets\"\n",
    "\n",
    "file_path = os.path.expanduser(CORPORA_PATH)\n",
    "files = glob.glob(os.path.join(file_path, \"*.set\"))\n",
    "\n",
    "def normalize_subject(X):\n",
    "    mean = X.mean(axis=(0, 2)).reshape(-1, 1)\n",
    "    std = X.std(axis=(0, 2)).reshape(-1, 1)\n",
    "    return (X - mean) / std\n",
    "\n",
    "def load_data_from_subject(filename, normalize=True):\n",
    "    data_mne = mne.io.read_raw_eeglab(filename, preload=True, event_id={\"0\": 1, \"1\": 2})\n",
    "    data_mne.filter(0, 20)\n",
    "    events = mne.find_events(data_mne)\n",
    "    epochs = mne.Epochs(\n",
    "        data_mne, events,\n",
    "        baseline=(None, 0), tmin=-0.1, tmax=0.7)\n",
    "\n",
    "    epochs.load_data()\n",
    "    \n",
    "    ch_names = epochs.ch_names\n",
    "    \n",
    "    X = epochs.get_data()[:, :-1]\n",
    "    y = (events[:, 2] == 2).astype('float')\n",
    "\n",
    "    if len(events) != len(epochs):\n",
    "        raise ValueError(\"Epochs events mismatch\")\n",
    "    if normalize: \n",
    "        X = normalize_subject(X)\n",
    "    \n",
    "    \n",
    "    return X, y \n",
    "\n",
    "def load_data(filenames):\n",
    "    X = None\n",
    "    y = None\n",
    "    for filename in filenames:\n",
    "        try:\n",
    "            X_subject, y_subject = load_data_from_subject(filename)\n",
    "\n",
    "            if X is None:\n",
    "                X, y = X_subject, y_subject\n",
    "            else:\n",
    "                print(X.shape, X_subject.shape)\n",
    "                X = np.vstack((X, X_subject))\n",
    "                print(y.shape, y_subject.shape)\n",
    "                y = np.vstack((y.reshape(-1,1), y_subject.reshape(-1,1)))\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando gpu 0\n"
     ]
    }
   ],
   "source": [
    "gpu_to_use = 0\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(gpu_to_use)\n",
    "\n",
    "print(\"Usando gpu {}\".format(gpu_to_use))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets appear as 2 in the third column\n",
    "\n",
    "\n",
    "We remove last channel as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# this line is to avoid output\n",
    "\n",
    "no_subjects_to_use = 45\n",
    "\n",
    "training_files = files[:no_subjects_to_use]\n",
    "testing_files = files[no_subjects_to_use:no_subjects_to_use+15]\n",
    "\n",
    "X_train, y_train = load_data(training_files)\n",
    "X_test, y_test = load_data(testing_files)\n",
    "\n",
    "X_train = X_train[:, :, :, np.newaxis]\n",
    "X_test = X_test[:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "activation = 'relu'\n",
    "\n",
    "n_kernels = 15\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation=activation, input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(3*n_kernels, (1, 13), padding='same',\n",
    "                activation=activation))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(256, activation=activation))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79704 samples, validate on 8856 samples\n",
      "Epoch 1/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.3510 - acc: 0.3707Epoch 00001: val_loss improved from inf to 1.22054, saving model to model.h5\n",
      "79704/79704 [==============================] - 9s 108us/step - loss: 1.3507 - acc: 0.3705 - val_loss: 1.2205 - val_acc: 0.3285\n",
      "Epoch 2/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.2372 - acc: 0.4337Epoch 00002: val_loss improved from 1.22054 to 1.21312, saving model to model.h5\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.2374 - acc: 0.4337 - val_loss: 1.2131 - val_acc: 0.3857\n",
      "Epoch 3/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.2251 - acc: 0.4885Epoch 00003: val_loss improved from 1.21312 to 1.20451, saving model to model.h5\n",
      "79704/79704 [==============================] - 8s 101us/step - loss: 1.2252 - acc: 0.4884 - val_loss: 1.2045 - val_acc: 0.4840\n",
      "Epoch 4/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.5016Epoch 00004: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.2165 - acc: 0.5014 - val_loss: 1.2137 - val_acc: 0.6191\n",
      "Epoch 5/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.2101 - acc: 0.5145Epoch 00005: val_loss improved from 1.20451 to 1.19835, saving model to model.h5\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.2102 - acc: 0.5147 - val_loss: 1.1983 - val_acc: 0.5872\n",
      "Epoch 6/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.2031 - acc: 0.5308Epoch 00006: val_loss improved from 1.19835 to 1.19127, saving model to model.h5\n",
      "79704/79704 [==============================] - 8s 101us/step - loss: 1.2032 - acc: 0.5307 - val_loss: 1.1913 - val_acc: 0.5740\n",
      "Epoch 7/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1978 - acc: 0.5372Epoch 00007: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1981 - acc: 0.5372 - val_loss: 1.1947 - val_acc: 0.5239\n",
      "Epoch 8/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1947 - acc: 0.5447Epoch 00008: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1944 - acc: 0.5448 - val_loss: 1.2763 - val_acc: 0.7484\n",
      "Epoch 9/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1851 - acc: 0.5600Epoch 00009: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1853 - acc: 0.5597 - val_loss: 1.1975 - val_acc: 0.5103\n",
      "Epoch 10/40\n",
      "79104/79704 [============================>.] - ETA: 0s - loss: 1.1810 - acc: 0.5636Epoch 00010: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 98us/step - loss: 1.1807 - acc: 0.5635 - val_loss: 1.2173 - val_acc: 0.6245\n",
      "Epoch 11/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1738 - acc: 0.5794Epoch 00011: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1740 - acc: 0.5793 - val_loss: 1.2083 - val_acc: 0.5697\n",
      "Epoch 12/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1664 - acc: 0.5867Epoch 00012: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1666 - acc: 0.5868 - val_loss: 1.2047 - val_acc: 0.5309\n",
      "Epoch 13/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1644 - acc: 0.5967Epoch 00013: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1643 - acc: 0.5967 - val_loss: 1.2136 - val_acc: 0.5810\n",
      "Epoch 14/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1582 - acc: 0.6096Epoch 00014: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1582 - acc: 0.6096 - val_loss: 1.2187 - val_acc: 0.6538\n",
      "Epoch 15/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1532 - acc: 0.6164Epoch 00015: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 98us/step - loss: 1.1532 - acc: 0.6162 - val_loss: 1.2735 - val_acc: 0.6657\n",
      "Epoch 16/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1527 - acc: 0.6135Epoch 00016: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1525 - acc: 0.6136 - val_loss: 1.2383 - val_acc: 0.7148\n",
      "Epoch 17/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1493 - acc: 0.6277Epoch 00017: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1493 - acc: 0.6277 - val_loss: 1.2311 - val_acc: 0.5916\n",
      "Epoch 18/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1517 - acc: 0.6339Epoch 00018: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1515 - acc: 0.6341 - val_loss: 1.2484 - val_acc: 0.6637\n",
      "Epoch 19/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1500 - acc: 0.6357Epoch 00019: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1500 - acc: 0.6358 - val_loss: 1.2744 - val_acc: 0.6887\n",
      "Epoch 20/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1504 - acc: 0.6418Epoch 00020: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1506 - acc: 0.6419 - val_loss: 1.2371 - val_acc: 0.6407\n",
      "Epoch 21/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1508 - acc: 0.6401Epoch 00021: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1507 - acc: 0.6401 - val_loss: 1.2430 - val_acc: 0.6618\n",
      "Epoch 22/40\n",
      "79104/79704 [============================>.] - ETA: 0s - loss: 1.1510 - acc: 0.6457Epoch 00022: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1505 - acc: 0.6456 - val_loss: 1.2473 - val_acc: 0.6257\n",
      "Epoch 23/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1504 - acc: 0.6461Epoch 00023: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1503 - acc: 0.6462 - val_loss: 1.2495 - val_acc: 0.6322\n",
      "Epoch 24/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1501 - acc: 0.6532Epoch 00024: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1504 - acc: 0.6531 - val_loss: 1.2527 - val_acc: 0.6483\n",
      "Epoch 25/40\n",
      "79104/79704 [============================>.] - ETA: 0s - loss: 1.1529 - acc: 0.6587Epoch 00025: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1531 - acc: 0.6586 - val_loss: 1.2770 - val_acc: 0.7367\n",
      "Epoch 26/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1533 - acc: 0.6606Epoch 00026: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1533 - acc: 0.6606 - val_loss: 1.2589 - val_acc: 0.6446\n",
      "Epoch 27/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1559 - acc: 0.6607Epoch 00027: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1561 - acc: 0.6607 - val_loss: 1.2518 - val_acc: 0.6303\n",
      "Epoch 28/40\n",
      "79104/79704 [============================>.] - ETA: 0s - loss: 1.1585 - acc: 0.6623Epoch 00028: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1588 - acc: 0.6619 - val_loss: 1.2496 - val_acc: 0.6319\n",
      "Epoch 29/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1566 - acc: 0.6611Epoch 00029: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1565 - acc: 0.6611 - val_loss: 1.2409 - val_acc: 0.6861\n",
      "Epoch 30/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1583 - acc: 0.6494Epoch 00030: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1585 - acc: 0.6495 - val_loss: 1.2472 - val_acc: 0.6050\n",
      "Epoch 31/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1589 - acc: 0.6612Epoch 00031: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1589 - acc: 0.6612 - val_loss: 1.2391 - val_acc: 0.6213\n",
      "Epoch 32/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1645 - acc: 0.6542Epoch 00032: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1642 - acc: 0.6543 - val_loss: 1.2494 - val_acc: 0.6489\n",
      "Epoch 33/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1649 - acc: 0.6598Epoch 00033: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1649 - acc: 0.6600 - val_loss: 1.2694 - val_acc: 0.6979\n",
      "Epoch 34/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1638 - acc: 0.6569Epoch 00034: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1638 - acc: 0.6569 - val_loss: 1.2540 - val_acc: 0.7182\n",
      "Epoch 35/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1651 - acc: 0.6613Epoch 00035: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1648 - acc: 0.6615 - val_loss: 1.2885 - val_acc: 0.7553\n",
      "Epoch 36/40\n",
      "79104/79704 [============================>.] - ETA: 0s - loss: 1.1667 - acc: 0.6599Epoch 00036: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1672 - acc: 0.6594 - val_loss: 1.2593 - val_acc: 0.6763\n",
      "Epoch 37/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1665 - acc: 0.6561Epoch 00037: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1666 - acc: 0.6564 - val_loss: 1.2469 - val_acc: 0.6963\n",
      "Epoch 38/40\n",
      "79360/79704 [============================>.] - ETA: 0s - loss: 1.1671 - acc: 0.6614Epoch 00038: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1669 - acc: 0.6614 - val_loss: 1.2490 - val_acc: 0.6469\n",
      "Epoch 39/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1701 - acc: 0.6563Epoch 00039: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 99us/step - loss: 1.1699 - acc: 0.6563 - val_loss: 1.2649 - val_acc: 0.6898\n",
      "Epoch 40/40\n",
      "79616/79704 [============================>.] - ETA: 0s - loss: 1.1727 - acc: 0.6584Epoch 00040: val_loss did not improve\n",
      "79704/79704 [==============================] - 8s 100us/step - loss: 1.1725 - acc: 0.6583 - val_loss: 1.2501 - val_acc: 0.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2007e9eb8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=40, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.10,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.7316319444444445\n",
      "Precision  = 0.20574643359453487\n",
      "Recall     = 0.21333333333333335\n",
      "ROC AUC    = 0.5473340364583333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.5415277777777778\n",
      "Precision  = 0.19585987261146498\n",
      "Recall     = 0.56375\n",
      "ROC AUC    = 0.5706050868055556\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_2 = load_model(\"model.h5\")\n",
    "\n",
    "y_pred = model_2.predict_classes(X_test)\n",
    "y_prob = model_2.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.45))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2842 - acc: 0.3579Epoch 00001: val_loss improved from inf to 1.22865, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 74us/step - loss: 1.2840 - acc: 0.3576 - val_loss: 1.2286 - val_acc: 0.3149\n",
      "Epoch 2/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.2306 - acc: 0.4305Epoch 00002: val_loss improved from 1.22865 to 1.21838, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2310 - acc: 0.4305 - val_loss: 1.2184 - val_acc: 0.2291\n",
      "Epoch 3/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.2226 - acc: 0.4576Epoch 00003: val_loss improved from 1.21838 to 1.19523, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2223 - acc: 0.4579 - val_loss: 1.1952 - val_acc: 0.4571\n",
      "Epoch 4/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.2129 - acc: 0.4866Epoch 00004: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2132 - acc: 0.4865 - val_loss: 1.1990 - val_acc: 0.4819\n",
      "Epoch 5/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.2049 - acc: 0.5096Epoch 00005: val_loss improved from 1.19523 to 1.17519, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.2044 - acc: 0.5097 - val_loss: 1.1752 - val_acc: 0.5609\n",
      "Epoch 6/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1983 - acc: 0.5193Epoch 00006: val_loss improved from 1.17519 to 1.17201, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1983 - acc: 0.5194 - val_loss: 1.1720 - val_acc: 0.4187\n",
      "Epoch 7/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1951 - acc: 0.5159Epoch 00007: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1950 - acc: 0.5168 - val_loss: 1.1759 - val_acc: 0.4503\n",
      "Epoch 8/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5249Epoch 00008: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1934 - acc: 0.5250 - val_loss: 1.1799 - val_acc: 0.5316\n",
      "Epoch 9/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1864 - acc: 0.5308Epoch 00009: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1862 - acc: 0.5315 - val_loss: 1.1931 - val_acc: 0.3713\n",
      "Epoch 10/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1853 - acc: 0.5354Epoch 00010: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1851 - acc: 0.5353 - val_loss: 1.1799 - val_acc: 0.4334\n",
      "Epoch 11/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1806 - acc: 0.5418Epoch 00011: val_loss improved from 1.17201 to 1.16285, saving model to model.with_maxpool.h5\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1806 - acc: 0.5417 - val_loss: 1.1629 - val_acc: 0.5158\n",
      "Epoch 12/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1789 - acc: 0.5474Epoch 00012: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1790 - acc: 0.5464 - val_loss: 1.1676 - val_acc: 0.4921\n",
      "Epoch 13/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1761 - acc: 0.5466Epoch 00013: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1763 - acc: 0.5463 - val_loss: 1.1726 - val_acc: 0.4368\n",
      "Epoch 14/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.5444Epoch 00014: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1768 - acc: 0.5443 - val_loss: 1.1921 - val_acc: 0.4278\n",
      "Epoch 15/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1712 - acc: 0.5557Epoch 00015: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1714 - acc: 0.5552 - val_loss: 1.1732 - val_acc: 0.5203\n",
      "Epoch 16/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1710 - acc: 0.5541Epoch 00016: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1710 - acc: 0.5540 - val_loss: 1.1954 - val_acc: 0.5282\n",
      "Epoch 17/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1697 - acc: 0.5557Epoch 00017: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1701 - acc: 0.5555 - val_loss: 1.1818 - val_acc: 0.4729\n",
      "Epoch 18/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1696 - acc: 0.5573Epoch 00018: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1692 - acc: 0.5572 - val_loss: 1.1818 - val_acc: 0.5598\n",
      "Epoch 19/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1708 - acc: 0.5578Epoch 00019: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1706 - acc: 0.5582 - val_loss: 1.2023 - val_acc: 0.7223\n",
      "Epoch 20/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1665 - acc: 0.5650Epoch 00020: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1666 - acc: 0.5650 - val_loss: 1.1918 - val_acc: 0.4842\n",
      "Epoch 21/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1695 - acc: 0.5651Epoch 00021: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1694 - acc: 0.5652 - val_loss: 1.2015 - val_acc: 0.4865\n",
      "Epoch 22/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1673 - acc: 0.5679Epoch 00022: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1673 - acc: 0.5677 - val_loss: 1.2067 - val_acc: 0.5609\n",
      "Epoch 23/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1664 - acc: 0.5625Epoch 00023: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1664 - acc: 0.5628 - val_loss: 1.1967 - val_acc: 0.5068\n",
      "Epoch 24/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1680 - acc: 0.5622Epoch 00024: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1677 - acc: 0.5621 - val_loss: 1.1863 - val_acc: 0.6569\n",
      "Epoch 25/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1685 - acc: 0.5650Epoch 00025: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 64us/step - loss: 1.1681 - acc: 0.5649 - val_loss: 1.2268 - val_acc: 0.7190\n",
      "Epoch 26/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1654 - acc: 0.5734Epoch 00026: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 66us/step - loss: 1.1653 - acc: 0.5738 - val_loss: 1.2172 - val_acc: 0.5316\n",
      "Epoch 27/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1688 - acc: 0.5724Epoch 00027: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1688 - acc: 0.5725 - val_loss: 1.2068 - val_acc: 0.5023\n",
      "Epoch 28/30\n",
      "87552/87674 [============================>.] - ETA: 0s - loss: 1.1673 - acc: 0.5697Epoch 00028: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1675 - acc: 0.5697 - val_loss: 1.2014 - val_acc: 0.4887\n",
      "Epoch 29/30\n",
      "86784/87674 [============================>.] - ETA: 0s - loss: 1.1674 - acc: 0.5722Epoch 00029: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1679 - acc: 0.5715 - val_loss: 1.2151 - val_acc: 0.6738\n",
      "Epoch 30/30\n",
      "87296/87674 [============================>.] - ETA: 0s - loss: 1.1721 - acc: 0.5714Epoch 00030: val_loss did not improve\n",
      "87674/87674 [==============================] - 6s 65us/step - loss: 1.1717 - acc: 0.5715 - val_loss: 1.2369 - val_acc: 0.6354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f8884048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.6778472222222223\n",
      "Precision  = 0.20906964656964658\n",
      "Recall     = 0.33520833333333333\n",
      "ROC AUC    = 0.5621011501736111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(2*n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(2*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2579 - acc: 0.2898Epoch 00001: val_loss improved from inf to 1.23357, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 9s 97us/step - loss: 1.2578 - acc: 0.2909 - val_loss: 1.2336 - val_acc: 0.3059\n",
      "Epoch 2/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2382 - acc: 0.4181Epoch 00002: val_loss improved from 1.23357 to 1.22315, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2384 - acc: 0.4181 - val_loss: 1.2232 - val_acc: 0.3341\n",
      "Epoch 3/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2305 - acc: 0.4623Epoch 00003: val_loss improved from 1.22315 to 1.21358, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2309 - acc: 0.4623 - val_loss: 1.2136 - val_acc: 0.4300\n",
      "Epoch 4/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2240 - acc: 0.4711Epoch 00004: val_loss improved from 1.21358 to 1.20041, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2239 - acc: 0.4719 - val_loss: 1.2004 - val_acc: 0.5609\n",
      "Epoch 5/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2180 - acc: 0.4968Epoch 00005: val_loss improved from 1.20041 to 1.19120, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2187 - acc: 0.4972 - val_loss: 1.1912 - val_acc: 0.4447\n",
      "Epoch 6/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.4846Epoch 00006: val_loss improved from 1.19120 to 1.18859, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2165 - acc: 0.4848 - val_loss: 1.1886 - val_acc: 0.4808\n",
      "Epoch 7/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2146 - acc: 0.5035Epoch 00007: val_loss improved from 1.18859 to 1.18811, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2145 - acc: 0.5036 - val_loss: 1.1881 - val_acc: 0.5068\n",
      "Epoch 8/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2128 - acc: 0.5062Epoch 00008: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2130 - acc: 0.5065 - val_loss: 1.1937 - val_acc: 0.4695\n",
      "Epoch 9/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2096 - acc: 0.5042Epoch 00009: val_loss improved from 1.18811 to 1.18605, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2098 - acc: 0.5034 - val_loss: 1.1861 - val_acc: 0.4944\n",
      "Epoch 10/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2102 - acc: 0.5025Epoch 00010: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2096 - acc: 0.5022 - val_loss: 1.1982 - val_acc: 0.5372\n",
      "Epoch 11/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2056 - acc: 0.5100Epoch 00011: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 83us/step - loss: 1.2053 - acc: 0.5102 - val_loss: 1.2001 - val_acc: 0.5192\n",
      "Epoch 12/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2089 - acc: 0.5082Epoch 00012: val_loss improved from 1.18605 to 1.18120, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2084 - acc: 0.5080 - val_loss: 1.1812 - val_acc: 0.5892\n",
      "Epoch 13/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2066 - acc: 0.5105Epoch 00013: val_loss improved from 1.18120 to 1.17853, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2063 - acc: 0.5108 - val_loss: 1.1785 - val_acc: 0.6005\n",
      "Epoch 14/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2039 - acc: 0.5178Epoch 00014: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2040 - acc: 0.5176 - val_loss: 1.1920 - val_acc: 0.5790\n",
      "Epoch 15/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2034 - acc: 0.5219Epoch 00015: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2036 - acc: 0.5214 - val_loss: 1.1926 - val_acc: 0.4819\n",
      "Epoch 16/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5125Epoch 00016: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2008 - acc: 0.5123 - val_loss: 1.1882 - val_acc: 0.5192\n",
      "Epoch 17/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2029 - acc: 0.5150Epoch 00017: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2024 - acc: 0.5146 - val_loss: 1.1859 - val_acc: 0.4808\n",
      "Epoch 18/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5163Epoch 00018: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1989 - acc: 0.5162 - val_loss: 1.1935 - val_acc: 0.5609\n",
      "Epoch 19/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1986 - acc: 0.5195Epoch 00019: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1983 - acc: 0.5194 - val_loss: 1.1957 - val_acc: 0.6027\n",
      "Epoch 20/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2001 - acc: 0.5298Epoch 00020: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2000 - acc: 0.5299 - val_loss: 1.1886 - val_acc: 0.5102\n",
      "Epoch 21/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1973 - acc: 0.5305Epoch 00021: val_loss improved from 1.17853 to 1.17227, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1972 - acc: 0.5306 - val_loss: 1.1723 - val_acc: 0.5282\n",
      "Epoch 22/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5220Epoch 00022: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1987 - acc: 0.5221 - val_loss: 1.1828 - val_acc: 0.5564\n",
      "Epoch 23/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2017 - acc: 0.5264Epoch 00023: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2023 - acc: 0.5266 - val_loss: 1.2311 - val_acc: 0.4921\n",
      "Epoch 24/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2010 - acc: 0.5248Epoch 00024: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.2016 - acc: 0.5249 - val_loss: 1.2268 - val_acc: 0.5508\n",
      "Epoch 25/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2047 - acc: 0.5183Epoch 00025: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.2053 - acc: 0.5186 - val_loss: 1.1934 - val_acc: 0.5508\n",
      "Epoch 26/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1973 - acc: 0.5213Epoch 00026: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 84us/step - loss: 1.1975 - acc: 0.5215 - val_loss: 1.1883 - val_acc: 0.5858\n",
      "Epoch 27/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.5303Epoch 00027: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1969 - acc: 0.5307 - val_loss: 1.1782 - val_acc: 0.6174\n",
      "Epoch 28/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1943 - acc: 0.5416Epoch 00028: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 85us/step - loss: 1.1947 - acc: 0.5415 - val_loss: 1.1951 - val_acc: 0.5519\n",
      "Epoch 29/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1935 - acc: 0.5352Epoch 00029: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 86us/step - loss: 1.1934 - acc: 0.5357 - val_loss: 1.2028 - val_acc: 0.6275\n",
      "Epoch 30/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.1950 - acc: 0.5363Epoch 00030: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 83us/step - loss: 1.1951 - acc: 0.5362 - val_loss: 1.1984 - val_acc: 0.4650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f3efd5c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.4284375\n",
      "Precision  = 0.18658280922431866\n",
      "Recall     = 0.723125\n",
      "ROC AUC    = 0.5781777647569444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with two layers but one simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(2*n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Conv2D(n_kernels, (14, 5), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87674 samples, validate on 886 samples\n",
      "Epoch 1/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2611 - acc: 0.3341Epoch 00001: val_loss improved from inf to 1.23793, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 8s 88us/step - loss: 1.2603 - acc: 0.3354 - val_loss: 1.2379 - val_acc: 0.6806\n",
      "Epoch 2/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2389 - acc: 0.4354Epoch 00002: val_loss improved from 1.23793 to 1.23455, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 77us/step - loss: 1.2385 - acc: 0.4356 - val_loss: 1.2346 - val_acc: 0.5023\n",
      "Epoch 3/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2300 - acc: 0.4530Epoch 00003: val_loss improved from 1.23455 to 1.23216, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2303 - acc: 0.4524 - val_loss: 1.2322 - val_acc: 0.3296\n",
      "Epoch 4/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2259 - acc: 0.4696Epoch 00004: val_loss improved from 1.23216 to 1.20799, saving model to model.2conv_with_maxpool.h5\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2262 - acc: 0.4699 - val_loss: 1.2080 - val_acc: 0.4707\n",
      "Epoch 5/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.4933Epoch 00005: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2189 - acc: 0.4926 - val_loss: 1.2386 - val_acc: 0.2269\n",
      "Epoch 6/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2161 - acc: 0.4894Epoch 00006: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2165 - acc: 0.4894 - val_loss: 1.2285 - val_acc: 0.4289\n",
      "Epoch 7/30\n",
      "87040/87674 [============================>.] - ETA: 0s - loss: 1.2121 - acc: 0.5043Epoch 00007: val_loss did not improve\n",
      "87674/87674 [==============================] - 7s 78us/step - loss: 1.2120 - acc: 0.5042 - val_loss: 1.2172 - val_acc: 0.4774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff1f3f581d0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.01,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.48006944444444444\n",
      "Precision  = 0.19064704451471662\n",
      "Recall     = 0.653125\n",
      "ROC AUC    = 0.5707269444444445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
