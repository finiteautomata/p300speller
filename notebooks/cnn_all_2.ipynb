{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for many subjects\n",
    "\n",
    "$$ x = y^2 + 2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import mne\n",
    "CORPORA_PATH = \"~/corpora/sets\"\n",
    "\n",
    "file_path = os.path.expanduser(CORPORA_PATH)\n",
    "files = glob.glob(os.path.join(file_path, \"*.set\"))\n",
    "\n",
    "def normalize_subject(X):\n",
    "    mean = X.mean(axis=(0, 2)).reshape(-1, 1)\n",
    "    std = X.std(axis=(0, 2)).reshape(-1, 1)\n",
    "    return (X - mean) / std\n",
    "\n",
    "def load_data(filename, normalize=True):\n",
    "    data_mne = mne.io.read_raw_eeglab(filename, preload=True, event_id={\"0\": 1, \"1\": 2})\n",
    "    data_mne.filter(0, 20)\n",
    "    events = mne.find_events(data_mne)\n",
    "    epochs = mne.Epochs(\n",
    "        data_mne, events,\n",
    "        baseline=(None, 0), tmin=-0.1, tmax=0.7)\n",
    "\n",
    "    epochs.load_data()\n",
    "    \n",
    "    ch_names = epochs.ch_names\n",
    "    \n",
    "    X = epochs.get_data()[:, :-1]\n",
    "    y = (events[:, 2] == 2).astype('float')\n",
    "\n",
    "    if len(events) != len(epochs):\n",
    "        raise ValueError(\"Epochs events mismatch\")\n",
    "    if normalize: \n",
    "        X = normalize_subject(X)\n",
    "    \n",
    "    \n",
    "    return X, y \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Targets appear as 2 in the third column\n",
    "\n",
    "\n",
    "We remove last channel as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN with more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "filenames = files\n",
    "\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "print(filenames)\n",
    "for filename in filenames:\n",
    "    try:\n",
    "        X_subject, y_subject = load_data(filename)\n",
    "\n",
    "        if X is None:\n",
    "            X, y = X_subject, y_subject\n",
    "        else:\n",
    "            X = np.vstack((X, X_subject))\n",
    "            y = np.vstack((y.reshape(-1,1), y_subject.reshape(-1,1)))\n",
    "    except ValueError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287640, 14, 104)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287640, 14, 104, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = X[:, :, :, np.newaxis]\n",
    "\n",
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((258876, 14, 104, 1), (258876, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_t, y, test_size=0.1, stratify=y)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232988 samples, validate on 25888 samples\n",
      "Epoch 1/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2976 - acc: 0.4104Epoch 00001: val_loss improved from inf to 1.23160, saving model to model.2.h5\n",
      "232988/232988 [==============================] - 90s 384us/step - loss: 1.2976 - acc: 0.4104 - val_loss: 1.2316 - val_acc: 0.5265\n",
      "Epoch 2/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2317 - acc: 0.4569Epoch 00002: val_loss improved from 1.23160 to 1.22918, saving model to model.2.h5\n",
      "232988/232988 [==============================] - 89s 382us/step - loss: 1.2317 - acc: 0.4569 - val_loss: 1.2292 - val_acc: 0.4601\n",
      "Epoch 3/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2264 - acc: 0.4603Epoch 00003: val_loss improved from 1.22918 to 1.22737, saving model to model.2.h5\n",
      "232988/232988 [==============================] - 89s 382us/step - loss: 1.2264 - acc: 0.4603 - val_loss: 1.2274 - val_acc: 0.4553\n",
      "Epoch 4/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2233 - acc: 0.4653Epoch 00004: val_loss improved from 1.22737 to 1.22073, saving model to model.2.h5\n",
      "232988/232988 [==============================] - 89s 382us/step - loss: 1.2233 - acc: 0.4653 - val_loss: 1.2207 - val_acc: 0.4867\n",
      "Epoch 5/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2227 - acc: 0.4625Epoch 00005: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2227 - acc: 0.4625 - val_loss: 1.2213 - val_acc: 0.5183\n",
      "Epoch 6/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2216 - acc: 0.4651Epoch 00006: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2216 - acc: 0.4651 - val_loss: 1.2229 - val_acc: 0.5160\n",
      "Epoch 7/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2211 - acc: 0.4618Epoch 00007: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2211 - acc: 0.4618 - val_loss: 1.2348 - val_acc: 0.3983\n",
      "Epoch 8/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2220 - acc: 0.4509Epoch 00008: val_loss improved from 1.22073 to 1.21983, saving model to model.2.h5\n",
      "232988/232988 [==============================] - 89s 382us/step - loss: 1.2220 - acc: 0.4509 - val_loss: 1.2198 - val_acc: 0.4307\n",
      "Epoch 9/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2243 - acc: 0.4460Epoch 00009: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2243 - acc: 0.4460 - val_loss: 1.2302 - val_acc: 0.6208\n",
      "Epoch 10/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2198 - acc: 0.4539Epoch 00010: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2198 - acc: 0.4539 - val_loss: 1.2218 - val_acc: 0.4305\n",
      "Epoch 11/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2238 - acc: 0.4486Epoch 00011: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2238 - acc: 0.4486 - val_loss: 1.2338 - val_acc: 0.5596\n",
      "Epoch 12/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2213 - acc: 0.4470Epoch 00012: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2213 - acc: 0.4470 - val_loss: 1.2275 - val_acc: 0.3737\n",
      "Epoch 13/50\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2229 - acc: 0.4483Epoch 00013: val_loss did not improve\n",
      "232988/232988 [==============================] - 88s 379us/step - loss: 1.2230 - acc: 0.4483 - val_loss: 1.2340 - val_acc: 0.3905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb1a6dbf98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=50, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.1,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.43391044361006814\n",
      "Precision  = 0.19811866099111883\n",
      "Recall     = 0.7863996662494785\n",
      "ROC AUC    = 0.6359560579217973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"model.2.h5\")\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with two layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(2*n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(5*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(n_kernels, (14, 1), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(Conv2D(2*n_kernels, (1, 13), padding='same',\n",
    "                activation='relu'))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232988 samples, validate on 25888 samples\n",
      "Epoch 1/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2404 - acc: 0.3876Epoch 00001: val_loss improved from inf to 1.23118, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 88s 377us/step - loss: 1.2404 - acc: 0.3876 - val_loss: 1.2312 - val_acc: 0.4926\n",
      "Epoch 2/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2241 - acc: 0.4836Epoch 00002: val_loss improved from 1.23118 to 1.22105, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 371us/step - loss: 1.2240 - acc: 0.4836 - val_loss: 1.2210 - val_acc: 0.4896\n",
      "Epoch 3/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.4927Epoch 00003: val_loss improved from 1.22105 to 1.21866, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 87s 372us/step - loss: 1.2185 - acc: 0.4927 - val_loss: 1.2187 - val_acc: 0.5652\n",
      "Epoch 4/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2139 - acc: 0.5055Epoch 00004: val_loss improved from 1.21866 to 1.21549, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 371us/step - loss: 1.2140 - acc: 0.5055 - val_loss: 1.2155 - val_acc: 0.5521\n",
      "Epoch 5/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2111 - acc: 0.5070Epoch 00005: val_loss improved from 1.21549 to 1.21280, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 371us/step - loss: 1.2111 - acc: 0.5070 - val_loss: 1.2128 - val_acc: 0.5290\n",
      "Epoch 6/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2082 - acc: 0.5031Epoch 00006: val_loss improved from 1.21280 to 1.20910, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.2082 - acc: 0.5031 - val_loss: 1.2091 - val_acc: 0.5268\n",
      "Epoch 7/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2066 - acc: 0.5116Epoch 00007: val_loss improved from 1.20910 to 1.20766, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.2067 - acc: 0.5116 - val_loss: 1.2077 - val_acc: 0.5651\n",
      "Epoch 8/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2026 - acc: 0.5113Epoch 00008: val_loss improved from 1.20766 to 1.20686, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 368us/step - loss: 1.2026 - acc: 0.5113 - val_loss: 1.2069 - val_acc: 0.5403\n",
      "Epoch 9/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2015 - acc: 0.5137Epoch 00009: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 371us/step - loss: 1.2014 - acc: 0.5137 - val_loss: 1.2077 - val_acc: 0.5426\n",
      "Epoch 10/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1989 - acc: 0.5174Epoch 00010: val_loss improved from 1.20686 to 1.20611, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 369us/step - loss: 1.1989 - acc: 0.5174 - val_loss: 1.2061 - val_acc: 0.5138\n",
      "Epoch 11/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1980 - acc: 0.5166Epoch 00011: val_loss improved from 1.20611 to 1.20466, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 85s 365us/step - loss: 1.1980 - acc: 0.5166 - val_loss: 1.2047 - val_acc: 0.5190\n",
      "Epoch 12/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1970 - acc: 0.5191Epoch 00012: val_loss improved from 1.20466 to 1.20293, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 85s 367us/step - loss: 1.1970 - acc: 0.5191 - val_loss: 1.2029 - val_acc: 0.5163\n",
      "Epoch 13/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1944 - acc: 0.5194Epoch 00013: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1944 - acc: 0.5194 - val_loss: 1.2051 - val_acc: 0.5577\n",
      "Epoch 14/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1926 - acc: 0.5233Epoch 00014: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1926 - acc: 0.5233 - val_loss: 1.2034 - val_acc: 0.5123\n",
      "Epoch 15/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1922 - acc: 0.5257Epoch 00015: val_loss improved from 1.20293 to 1.20201, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 371us/step - loss: 1.1922 - acc: 0.5257 - val_loss: 1.2020 - val_acc: 0.5314\n",
      "Epoch 16/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1911 - acc: 0.5247Epoch 00016: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1911 - acc: 0.5247 - val_loss: 1.2045 - val_acc: 0.5500\n",
      "Epoch 17/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1897 - acc: 0.5294Epoch 00017: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1897 - acc: 0.5294 - val_loss: 1.2049 - val_acc: 0.4604\n",
      "Epoch 18/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1879 - acc: 0.5285Epoch 00018: val_loss improved from 1.20201 to 1.20077, saving model to model.2conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1879 - acc: 0.5285 - val_loss: 1.2008 - val_acc: 0.5178\n",
      "Epoch 19/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1878 - acc: 0.5294Epoch 00019: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1878 - acc: 0.5294 - val_loss: 1.2027 - val_acc: 0.4962\n",
      "Epoch 20/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1862 - acc: 0.5249Epoch 00020: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1862 - acc: 0.5249 - val_loss: 1.2063 - val_acc: 0.5914\n",
      "Epoch 21/30\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.1848 - acc: 0.5320Epoch 00021: val_loss did not improve\n",
      "232988/232988 [==============================] - 86s 370us/step - loss: 1.1847 - acc: 0.5320 - val_loss: 1.2027 - val_acc: 0.5044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb1a75c518>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.2conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=30, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.1,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.5206160478375748\n",
      "Precision  = 0.21790127328608166\n",
      "Recall     = 0.7246558197747184\n",
      "ROC AUC    = 0.6565931740221097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"model.2conv_with_maxpool.h5\")\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv with two layers but one simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Conv2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "n_kernels = 10\n",
    "model.add(Conv2D(n_kernels, (14, 14), padding='same', \n",
    "                activation='relu', input_shape=(14, 104, 1)))\n",
    "model.add(MaxPool2D((1, 4)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # using the cross-entropy loss function\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy']) # reporting the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232988 samples, validate on 25888 samples\n",
      "Epoch 1/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2591 - acc: 0.4142Epoch 00001: val_loss improved from inf to 1.23709, saving model to model.3conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 22s 93us/step - loss: 1.2591 - acc: 0.4142 - val_loss: 1.2371 - val_acc: 0.4066\n",
      "Epoch 2/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2445 - acc: 0.4198Epoch 00002: val_loss improved from 1.23709 to 1.22994, saving model to model.3conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 21s 91us/step - loss: 1.2445 - acc: 0.4198 - val_loss: 1.2299 - val_acc: 0.5048\n",
      "Epoch 3/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2358 - acc: 0.4200Epoch 00003: val_loss improved from 1.22994 to 1.22659, saving model to model.3conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 21s 91us/step - loss: 1.2358 - acc: 0.4199 - val_loss: 1.2266 - val_acc: 0.3874\n",
      "Epoch 4/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2318 - acc: 0.4206Epoch 00004: val_loss improved from 1.22659 to 1.22593, saving model to model.3conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 21s 91us/step - loss: 1.2317 - acc: 0.4206 - val_loss: 1.2259 - val_acc: 0.5162\n",
      "Epoch 5/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2306 - acc: 0.4144Epoch 00005: val_loss improved from 1.22593 to 1.22070, saving model to model.3conv_with_maxpool.h5\n",
      "232988/232988 [==============================] - 21s 91us/step - loss: 1.2306 - acc: 0.4144 - val_loss: 1.2207 - val_acc: 0.4313\n",
      "Epoch 6/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2298 - acc: 0.4214- ETA: 0s - loss: 1.2300 - aEpoch 00006: val_loss did not improve\n",
      "232988/232988 [==============================] - 21s 90us/step - loss: 1.2298 - acc: 0.4214 - val_loss: 1.2228 - val_acc: 0.4159\n",
      "Epoch 7/10\n",
      "232960/232988 [============================>.] - ETA: 0s - loss: 1.2296 - acc: 0.4279Epoch 00007: val_loss did not improve\n",
      "232988/232988 [==============================] - 21s 89us/step - loss: 1.2296 - acc: 0.4279 - val_loss: 1.2209 - val_acc: 0.4181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb19cfee80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpointer = ModelCheckpoint(filepath='model.3conv_with_maxpool.h5', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=10, \n",
    "    batch_size=256, class_weight={0:1, 1:6}, validation_split=0.1,\n",
    "    callbacks=[checkpointer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy   = 0.4183354192740926\n",
      "Precision  = 0.1965838035687052\n",
      "Recall     = 0.8066332916145181\n",
      "ROC AUC    = 0.6368764216291085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "y_prob = model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\"\"\n",
    "Accuracy   = {}\n",
    "Precision  = {}\n",
    "Recall     = {}\n",
    "ROC AUC    = {}\n",
    "\"\"\".format(accuracy, precision, recall, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
